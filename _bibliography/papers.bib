---
---


@article{wang2023promptagent,
  title={PromptAgent: Strategic Planning with Language Models Enables Expert-level Prompt Optimization},
  author={Wang, Xinyuan and Li, Chenxi and Wang, Zhen and Bai, Fan and Luo, Haotian and Zhang, Jiayou and Jojic, Nebojsa and Xing, Eric P and Hu, Zhiting},
  journal={arXiv preprint arXiv:2310.16427},
  year={2023},
  pdf={https://arxiv.org/pdf/2310.16427.pdf},
  code={https://github.com/XinyuanWangCS/PromptAgent},
  poster={promptagnet_poster_2023.pdf},
  preview={promptagent_header.png},
  abstract={Highly effective, task-specific prompts are often heavily engineered by experts to integrate detailed instructions and domain insights based on a deep understanding of both instincts of large language models (LLMs) and the intricacies of the target task. However, automating the generation of such expert-level prompts remains elusive. Existing prompt optimization methods tend to overlook the depth of domain knowledge and struggle to efficiently explore the vast space of expert-level prompts. Addressing this, we present PromptAgent, an optimization method that autonomously crafts prompts equivalent in quality to those handcrafted by experts. At its core, PromptAgent views prompt optimization as a strategic planning problem and employs a principled planning algorithm, rooted in Monte Carlo tree search, to strategically navigate the expert-level prompt space. Inspired by human-like trial-and-error exploration, PromptAgent induces precise expert-level insights and in-depth instructions by reflecting on model errors and generating constructive error feedback. Such a novel framework allows the agent to iteratively examine intermediate prompts (states), refine them based on error feedbacks (actions), simulate future rewards, and search for high-reward paths leading to expert prompts. We apply PromptAgent to 12 tasks spanning three practical domains: BIG-Bench Hard (BBH), as well as domain-specific and general NLP tasks, showing it significantly outperforms strong Chain-of-Thought and recent prompt optimization baselines. Extensive analyses emphasize its capability to craft expert-level, detailed, and domain-insightful prompts with great efficiency and generalizability.},
}

@INPROCEEDINGS{9696145,
  author={Wang, Xinyuan and Tao, Make and Wang, Runpu and Zhang, Likui},
  booktitle={2021 2nd International Conference on Big Data & Artificial Intelligence & Software Engineering (ICBASE)}, 
  title={Reduce the medical burden: An automatic medical triage system using text classification BERT based on Transformer structure}, 
  year={2021},
  pages={679-685},
  doi={10.1109/ICBASE53849.2021.00133},
  preview={medicalbert.png}}

@inproceedings{10.1145/3430036.3430068,
author = {Zhou, Fangfang and Chen, Qi'an and Cui, Yunlong and Wang, Xinyuan and Ma, Hongxu and Zhao, Ying and Li, Xiaoli},
title = {A Fast Method for Detecting Minority Structures in a Graph},
year = {2020},
isbn = {9781450387507},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3430036.3430068},
doi = {10.1145/3430036.3430068},
abstract = {A graph contains plentiful structures. Some minority structures are important, such as high degree nodes and bridges. Detecting these minority structures is beneficial to accelerate computational graph analysis and improve the comprehension of graph visualization. Regarding four typical minority structures, this paper proposes two algorithms to detect these structures fast and efficiently. A set of experiments demonstrate the effectiveness of the proposed algorithms.},
booktitle = {Proceedings of the 13th International Symposium on Visual Information Communication and Interaction},
articleno = {26},
numpages = {2},
keywords = {graph sampling, graph anomaly detection, graph visualization},
location = {Eindhoven, Netherlands},
series = {VINCI '20},
preview={fastmethod.png}
}


