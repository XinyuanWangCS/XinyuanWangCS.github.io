---
layout: about
title: about
permalink: /
subtitle: Hi! I am Xinyuan Wang (王心远).

profile:
  align: right
  image: me.png
  image_circular: false # crops the image to make it circular
  #address: 
  #  <p>3869 Miramar st. Box 1214</p>
  #  <p>La Jolla, California, USA, 92092</p>

news: true  # includes a list of news items
selected_papers: true # includes a list of papers marked as "selected={true}"
social: true  # includes social icons at the bottom of the page
---

I am an incoming Ph.D. student at HKU, mentored by Prof. [Tao Yu](https://taoyds.github.io/). I obtained my master's degree from University of California, San Diego (UCSD). I was luckily to be mentored two distinguished professors at UCSD in Natural Language Processing and Computer Vision - Prof. [Zhiting Hu](http://zhiting.ucsd.edu/) and Prof. [Zhuowen Tu](https://pages.ucsd.edu/~ztu/). Prior to my study at UCSD, I graduated from Central South University (CSU) in Hunan, China, where I was mentored by Prof. [Ying Zhao](https://faculty.csu.edu.cn/zhaoying). 

Research Interests
------
- **Artificial Intelligence Agents**: Designing and developing LLM/VLM based agent system that can execute in real-world environments.
- **Large Language Models (LLMs) with World Models**: Augmenting LLMs with a world model formulation to enable principled decision-making, planning, and simulation. Enhancing the LLM's abilities in reasoning, planning, and interacting with the world. ([LLM Reasoners](https://www.llm-reasoners.net/))
- **Foundation Model Prompting**: Employing interpretable prompting to bridge the domain gap between user objectives and the outputs of foundation models. Effectively boosting the performance of foundation models on complex tasks through efficient and effective prompting. ([PromptAgent](https://arxiv.org/abs/2310.16427))


Research Overview
------
My research interests are LLM Augmentation (Prompting, Reasoning), LLM Agent, Unsupervised Learning (Generative Models), and Multi-modal Models. In Prof. Zhiting Hu's group, I worked on automatic LLM prompt optimization with Zhen. Recently our paper [PromptAgent: Strategic Planning with Language Models Enables Expert-level Prompt Optimization](https://arxiv.org/abs/2310.16427) is accepted by [ICLR 2024](https://iclr.cc/). I am also working on LLM Reasoning by contributing to the [LLM Reasoners](https://www.llm-reasoners.net/) library, which ensembles the most recent LLM reasoning methods and models. In Prof. Zhuowen Tu's group, we are working on how to inprove diffusion models' conceptual performance with an end-to-end loss. During my undergraduate years, I was mentored by Prof. Ying Zhao and worked on Interpretation of Convolutional Neural Networks and Visualization. Here is my graduate thesis: [The Research on The Interpretability Method of DeepNeural Network Based on Average Image](assets\pdf\graduate_thesis.pdf)

How to contact me
------
Email: xiw136@ucsd.edu (till Jun. 2024) / xywang626@gmail.com

