---
layout: about
title: about
permalink: /
subtitle: Welcome!

profile:
  align: right
  image: me.png
  image_circular: false # crops the image to make it circular
  address: 
    <p>3869 Miramar st. Box 1214</p>
    <p>La Jolla, California, USA, 92092</p>

news: true  # includes a list of news items
selected_papers: true # includes a list of papers marked as "selected={true}"
social: true  # includes social icons at the bottom of the page
---

Hi! I am now a second-year MSCS student at University of California, San Diego (UCSD), expected to graduate in Jun. 2024. And I plan to pursue a Ph.D. in the future. I am luckily to be mentored by professors at UCSD in both Natural Language Processing and Computer Vision, and have hands-on experiences in both fields. I am now mentored by Prof. [Zhiting Hu](http://zhiting.ucsd.edu/) and Postdoc. [Zhen Wang](https://zhenwang9102.github.io/) in Large Language Model (LLM) Reasoning, Agent, and Prompting. I am also mentored by Prof. [Zhuowen Tu](https://pages.ucsd.edu/~ztu/) in generative models (diffusion model). Before UCSD, I graduated from Central South University (CSU) in Hunan, China, mentored by Prof. [Ying Zhao](https://faculty.csu.edu.cn/zhaoying). 

Research Interests
------
- **Large Language Models (LLMs) with World Models**: Augmenting LLMs with interfaces to world models and mechanisms to understand and process world information, thereby enabling them to address real-world challenges more effectively. ([LLM Reasoners](https://www.llm-reasoners.net/))
- **Foundation Model Inference Enhancement**: Foundation models demonstrate remarkable capabilities across a range of tasks. However, due to limitations in how we interact with them, their inference abilities are not fully exploited. One promising direction is to explore expert-level prompt optimization, bridging the gap between the model's inherent distribution and the specific distribution of tasks ([PromptAgent](https://arxiv.org/abs/2310.16427))
- **Conceptual Enhancement of Generative Models**: While large generative models can produce data with high fidelity and diversity, but they can only learn conceptual alignment implicitly. This can result in conceptual errors and incorrect heuristics. By focusing on conceptual enhancement, we can improve the reliability and interpretability of these models.

Research Overview
------
My research interests are LLM Augmentation (Prompting, Reasoning), LLM Agent, Unsupervised Learning (Generative Models), and Multi-modal Models. In Prof. Zhiting Hu's group, I worked on automatic LLM prompt optimization with Zhen. And recently we have a preprint paper, [PromptAgent: Strategic Planning with Language Models Enables Expert-level Prompt Optimization](https://arxiv.org/abs/2310.16427), under review of ICLR 2024 now. I am also working on LLM Reasoning by contributing to the [LLM Reasoners](https://www.llm-reasoners.net/) library, which ensembles the most recent LLM reasoning methods and models. In Prof. Zhuowen Tu's group, we are working on how to inprove diffusion models' conceptual performance with an end-to-end loss. During my undergraduate years, I was mentored by Prof. Ying Zhao and worked on Interpretation of Convolutional Neural Networks and Visualization. Here is my graduate thesis: [The Research on The Interpretability Method of DeepNeural Network Based on Average Image](assets\pdf\graduate_thesis.pdf)

How to contact me
------
Email: xiw136@ucsd.edu (till Jun. 2024) / xywang626@gmail.com

